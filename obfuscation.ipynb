{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":639622,"sourceType":"datasetVersion","datasetId":316368},{"sourceId":9012248,"sourceType":"datasetVersion","datasetId":5430025},{"sourceId":9038628,"sourceType":"datasetVersion","datasetId":5448783}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom keras.models import load_model\nfrom sklearn.preprocessing import OneHotEncoder\nimport librosa\n\n# Load the saved model\nmodel = load_model('/kaggle/input/h5model/trymodel.h5')\n\n# Function to extract MFCC features\ndef extract_mfcc(filename):\n    y, sr = librosa.load(filename, duration=3, offset=0.5)\n    mfcc = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T, axis=0)\n    return mfcc\n\n# Assuming you have a test dataset in the same directory format as the training dataset\ntest_paths = []\ntest_labels = []\nfor dirname, _, filenames in os.walk('/kaggle/input/toronto-emotional-speech-set-tess'):\n    for filename in filenames:\n        test_paths.append(os.path.join(dirname, filename))\n        label = filename.split('_')[-1]\n        label = label.split('.')[0]\n        test_labels.append(label.lower())\n\n# Create a dataframe for the test dataset\ntest_df = pd.DataFrame()\ntest_df['speech'] = test_paths\ntest_df['label'] = test_labels\n\n# Extract MFCC features for the test dataset\nX_test_mfcc = test_df['speech'].apply(lambda x: extract_mfcc(x))\n\nX_test = [x for x in X_test_mfcc]\nX_test = np.array(X_test)\nX_test = np.expand_dims(X_test, -1)\n\n# One-hot encode the labels for the test dataset\nenc = OneHotEncoder()\ny_test = enc.fit_transform(test_df[['label']])\ny_test = y_test.toarray()\n\n# Evaluate the model on the test dataset\nloss, accuracy = model.evaluate(X_test, y_test)\n\nprint(f'Test Accuracy: {accuracy * 100:.2f}%')\n","metadata":{"execution":{"iopub.status.busy":"2024-07-26T09:32:07.006221Z","iopub.execute_input":"2024-07-26T09:32:07.007038Z","iopub.status.idle":"2024-07-26T09:35:27.752253Z","shell.execute_reply.started":"2024-07-26T09:32:07.007004Z","shell.execute_reply":"2024-07-26T09:35:27.751294Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-07-26 09:32:10.396980: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-26 09:32:10.397103: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-26 09:32:10.560862: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0013\nTest Accuracy: 99.86%\n","output_type":"stream"}]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-07-26T09:36:53.045499Z","iopub.execute_input":"2024-07-26T09:36:53.046179Z","iopub.status.idle":"2024-07-26T09:36:53.073469Z","shell.execute_reply.started":"2024-07-26T09:36:53.046148Z","shell.execute_reply":"2024-07-26T09:36:53.072567Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m264,192\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)              │           \u001b[38;5;34m455\u001b[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">264,192</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">455</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m305,801\u001b[0m (1.17 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">305,801</span> (1.17 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m305,799\u001b[0m (1.17 MB)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">305,799</span> (1.17 MB)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n</pre>\n"},"metadata":{}}]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom keras.models import load_model\nfrom sklearn.preprocessing import OneHotEncoder\nimport librosa\n\n# Load the saved model\nmodel = load_model('/kaggle/input/obfuscate/obfuscated_model.h5')\n\n# Function to extract MFCC features\ndef extract_mfcc(filename):\n    y, sr = librosa.load(filename, duration=3, offset=0.5)\n    mfcc = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T, axis=0)\n    return mfcc\n\n# Assuming you have a test dataset in the same directory format as the training dataset\ntest_paths = []\ntest_labels = []\nfor dirname, _, filenames in os.walk('/kaggle/input/toronto-emotional-speech-set-tess'):\n    for filename in filenames:\n        test_paths.append(os.path.join(dirname, filename))\n        label = filename.split('_')[-1]\n        label = label.split('.')[0]\n        test_labels.append(label.lower())\n\n# Create a dataframe for the test dataset\ntest_df = pd.DataFrame()\ntest_df['speech'] = test_paths\ntest_df['label'] = test_labels\n\n# Extract MFCC features for the test dataset\nX_test_mfcc = test_df['speech'].apply(lambda x: extract_mfcc(x))\n\nX_test = [x for x in X_test_mfcc]\nX_test = np.array(X_test)\nX_test = np.expand_dims(X_test, -1)\n\n# One-hot encode the labels for the test dataset\nenc = OneHotEncoder()\ny_test = enc.fit_transform(test_df[['label']])\ny_test = y_test.toarray()\n\n# Evaluate the model on the test dataset\nloss, accuracy = model.evaluate(X_test, y_test)\n\nprint(f'Test Accuracy: {accuracy * 100:.2f}%')\n","metadata":{"execution":{"iopub.status.busy":"2024-07-26T09:36:55.940884Z","iopub.execute_input":"2024-07-26T09:36:55.941255Z","iopub.status.idle":"2024-07-26T09:38:30.837564Z","shell.execute_reply.started":"2024-07-26T09:36:55.941226Z","shell.execute_reply":"2024-07-26T09:38:30.836196Z"},"trusted":true},"execution_count":3,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[3], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m y_test \u001b[38;5;241m=\u001b[39m y_test\u001b[38;5;241m.\u001b[39mtoarray()\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the test dataset\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;250m \u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m100\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/trainers/trainer.py:993\u001b[0m, in \u001b[0;36mTrainer._assert_compile_called\u001b[0;34m(self, method_name)\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    992\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalling `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 993\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n","\u001b[0;31mValueError\u001b[0m: You must call `compile()` before using the model."],"ename":"ValueError","evalue":"You must call `compile()` before using the model.","output_type":"error"}]},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nfrom keras.models import load_model\nfrom keras.optimizers import Adam\nfrom keras.losses import CategoricalCrossentropy\nfrom keras.metrics import Accuracy\nfrom sklearn.preprocessing import OneHotEncoder\nimport librosa\n\n# Load the saved model\nmodel = load_model('/kaggle/input/obfuscate/obfuscated_model.h5')\n\n# Compile the model\nmodel.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=[Accuracy()])\n\n# Function to extract MFCC features\ndef extract_mfcc(filename):\n    y, sr = librosa.load(filename, duration=3, offset=0.5)\n    mfcc = np.mean(librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40).T, axis=0)\n    return mfcc\n\n# Assuming you have a test dataset in the same directory format as the training dataset\ntest_paths = []\ntest_labels = []\nfor dirname, _, filenames in os.walk('/kaggle/input/toronto-emotional-speech-set-tess'):\n    for filename in filenames:\n        test_paths.append(os.path.join(dirname, filename))\n        label = filename.split('_')[-1]\n        label = label.split('.')[0]\n        test_labels.append(label.lower())\n\n# Create a dataframe for the test dataset\ntest_df = pd.DataFrame()\ntest_df['speech'] = test_paths\ntest_df['label'] = test_labels\n\n# Extract MFCC features for the test dataset\nX_test_mfcc = test_df['speech'].apply(lambda x: extract_mfcc(x))\n\nX_test = [x for x in X_test_mfcc]\nX_test = np.array(X_test)\nX_test = np.expand_dims(X_test, -1)\n\n# One-hot encode the labels for the test dataset\nenc = OneHotEncoder()\ny_test = enc.fit_transform(test_df[['label']])\ny_test = y_test.toarray()\n\n# Evaluate the model on the test dataset\nloss, accuracy = model.evaluate(X_test, y_test)\n\nprint(f'Test Accuracy: {accuracy * 100:.2f}%')\n","metadata":{"execution":{"iopub.status.busy":"2024-07-26T09:41:12.781517Z","iopub.execute_input":"2024-07-26T09:41:12.781877Z","iopub.status.idle":"2024-07-26T09:42:45.798826Z","shell.execute_reply.started":"2024-07-26T09:41:12.781849Z","shell.execute_reply":"2024-07-26T09:42:45.797936Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"\u001b[1m175/175\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0000e+00 - loss: 2.0763\nTest Accuracy: 0.00%\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}